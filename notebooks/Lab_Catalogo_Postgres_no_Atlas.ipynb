{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Catalogando PostgreSQL no Apache Atlas\n",
    "\n",
    "## A Import√¢ncia do Cat√°logo de Dados\n",
    "\n",
    "### Por que Catalogar Dados?\n",
    "\n",
    "Em organiza√ß√µes modernas, os dados est√£o espalhados por m√∫ltiplos sistemas, formatos e localiza√ß√µes. Um **cat√°logo de dados** √© essencial para:\n",
    "\n",
    "- **Descoberta**: Encontrar rapidamente datasets relevantes\n",
    "- **Compreens√£o**: Entender estrutura, significado e qualidade dos dados\n",
    "- **Linhagem**: Rastrear origem e transforma√ß√µes dos dados\n",
    "- **Governan√ßa**: Aplicar pol√≠ticas de seguran√ßa e compliance\n",
    "- **Colabora√ß√£o**: Facilitar compartilhamento entre equipes\n",
    "- **Produtividade**: Reduzir tempo de an√°lise e desenvolvimento\n",
    "\n",
    "### Metadados: O DNA dos Dados\n",
    "\n",
    "Os **metadados** s√£o informa√ß√µes sobre os dados que incluem:\n",
    "\n",
    "- **Estruturais**: Esquemas, tipos, relacionamentos\n",
    "- **Descritivos**: Nomes, descri√ß√µes, tags, gloss√°rios\n",
    "- **Operacionais**: Frequ√™ncia de uso, performance, qualidade\n",
    "- **Administrativos**: Propriet√°rios, permiss√µes, pol√≠ticas\n",
    "\n",
    "## Apache Atlas: Hist√≥ria e Evolu√ß√£o\n",
    "\n",
    "### Origens (2015-2017)\n",
    "\n",
    "O **Apache Atlas** nasceu da necessidade da Hortonworks de gerenciar metadados no ecossistema Hadoop:\n",
    "\n",
    "- **2015**: Projeto iniciado pela Hortonworks\n",
    "- **2016**: Doa√ß√£o para Apache Software Foundation\n",
    "- **2017**: Primeira vers√£o est√°vel (0.8)\n",
    "\n",
    "### Caracter√≠sticas Principais\n",
    "\n",
    "- **Governan√ßa Unificada**: Cat√°logo centralizado para Big Data\n",
    "- **Linhagem Autom√°tica**: Rastreamento de transforma√ß√µes\n",
    "- **Classifica√ß√£o**: Tags e tipos personalizados\n",
    "- **Busca Avan√ßada**: Interface web intuitiva\n",
    "- **Integra√ß√£o**: Conectores para Hive, HBase, Kafka, etc.\n",
    "\n",
    "### Arquitetura\n",
    "\n",
    "- **Core**: Motor de metadados baseado em grafos\n",
    "- **Storage**: HBase para persist√™ncia\n",
    "- **Search**: Apache Solr para indexa√ß√£o\n",
    "- **Messaging**: Apache Kafka para eventos\n",
    "- **Security**: Integra√ß√£o com Ranger e Kerberos\n",
    "\n",
    "### Casos de Uso\n",
    "\n",
    "- **Data Lakes**: Cataloga√ß√£o de datasets em HDFS\n",
    "- **Data Warehouses**: Metadados de tabelas e views\n",
    "- **ETL Pipelines**: Linhagem de transforma√ß√µes\n",
    "- **Compliance**: Auditoria e classifica√ß√£o de dados sens√≠veis\n",
    "\n",
    "## Objetivo do Lab\n",
    "\n",
    "Neste laborat√≥rio, vamos:\n",
    "\n",
    "1. **Conectar** ao banco PostgreSQL Northwind\n",
    "2. **Extrair** metadados de tabelas e colunas\n",
    "3. **Catalogar** no Apache Atlas via API REST\n",
    "4. **Visualizar** o cat√°logo na interface web\n",
    "\n",
    "**Resultado**: Cat√°logo completo com 14 tabelas e suas colunas integradas ao Atlas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 1: Configura√ß√£o e Importa√ß√µes\n",
    "\n",
    "Esta c√©lula configura todas as depend√™ncias e par√¢metros necess√°rios para conectar ao PostgreSQL e Apache Atlas.\n",
    "\n",
    "**O que faz:**\n",
    "- Importa bibliotecas para HTTP, banco de dados e manipula√ß√£o de dados\n",
    "- Define URLs e credenciais de conex√£o\n",
    "- Configura autentica√ß√£o HTTP Basic para Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√£o das bibliotecas necess√°rias\n",
    "import requests                    # Para fazer requisi√ß√µes HTTP ao Atlas\n",
    "from requests.auth import HTTPBasicAuth  # Para autentica√ß√£o HTTP Basic\n",
    "import psycopg2                   # Driver para conectar ao PostgreSQL\n",
    "import pandas as pd               # Para manipula√ß√£o de dados em DataFrames\n",
    "import json                       # Para trabalhar com dados JSON\n",
    "\n",
    "# Configura√ß√µes do Apache Atlas\n",
    "ATLAS_URL = \"http://atlas:21000\"  # URL do servidor Atlas (container Docker)\n",
    "ATLAS_USER = \"admin\"              # Usu√°rio padr√£o do Atlas\n",
    "ATLAS_PASSWORD = \"admin\"          # Senha padr√£o do Atlas\n",
    "\n",
    "# Configura√ß√µes do PostgreSQL\n",
    "POSTGRES_CONFIG = {\n",
    "    \"host\": \"postgres_erp\",        # Nome do container PostgreSQL\n",
    "    \"port\": 5432,                  # Porta padr√£o do PostgreSQL\n",
    "    \"database\": \"northwind\",       # Nome do banco de dados\n",
    "    \"user\": \"postgres\",            # Usu√°rio do banco\n",
    "    \"password\": \"postgres\"         # Senha do banco\n",
    "}\n",
    "\n",
    "# Configurar autentica√ß√£o HTTP Basic para Atlas\n",
    "auth = HTTPBasicAuth(ATLAS_USER, ATLAS_PASSWORD)\n",
    "print(\"‚úÖ Configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 2: Extra√ß√£o de Metadados do PostgreSQL\n",
    "\n",
    "Esta c√©lula conecta ao PostgreSQL e extrai metadados estruturais de todas as tabelas.\n",
    "\n",
    "**O que faz:**\n",
    "- Conecta ao banco PostgreSQL Northwind\n",
    "- Consulta o `information_schema` para obter lista de tabelas\n",
    "- Para cada tabela, extrai informa√ß√µes das colunas (nome, tipo, nullable)\n",
    "- Organiza os metadados em um dicion√°rio Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postgres_metadata():\n",
    "    \"\"\"Extrai metadados estruturais do PostgreSQL\"\"\"\n",
    "    # Estabelece conex√£o com o PostgreSQL usando as configura√ß√µes definidas\n",
    "    conn = psycopg2.connect(**POSTGRES_CONFIG)\n",
    "    \n",
    "    # Query SQL para buscar todas as tabelas do schema 'public'\n",
    "    tables_df = pd.read_sql(\"\"\"\n",
    "        SELECT table_name \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema = 'public'  -- Apenas tabelas do schema p√∫blico\n",
    "        ORDER BY table_name            -- Ordena alfabeticamente\n",
    "    \"\"\", conn)\n",
    "    \n",
    "    # Dicion√°rio para armazenar metadados de todas as tabelas\n",
    "    metadata = {}\n",
    "    \n",
    "    # Itera sobre cada tabela encontrada\n",
    "    for _, row in tables_df.iterrows():\n",
    "        table_name = row['table_name']  # Nome da tabela atual\n",
    "        \n",
    "        # Query SQL para buscar colunas da tabela espec√≠fica\n",
    "        columns_df = pd.read_sql(\"\"\"\n",
    "            SELECT column_name, data_type, is_nullable\n",
    "            FROM information_schema.columns \n",
    "            WHERE table_name = %s AND table_schema = 'public'\n",
    "            ORDER BY ordinal_position  -- Ordena pela posi√ß√£o original da coluna\n",
    "        \"\"\", conn, params=[table_name])  # Usa par√¢metro para evitar SQL injection\n",
    "        \n",
    "        # Converte DataFrame para lista de dicion√°rios e armazena\n",
    "        metadata[table_name] = columns_df.to_dict('records')\n",
    "    \n",
    "    # Fecha a conex√£o com o banco\n",
    "    conn.close()\n",
    "    return metadata\n",
    "\n",
    "# Executa a extra√ß√£o de metadados\n",
    "postgres_metadata = get_postgres_metadata()\n",
    "print(f\"üìã {len(postgres_metadata)} tabelas encontradas\")\n",
    "print(f\"Exemplo: {list(postgres_metadata.keys())[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÑÔ∏è Passo 3: Cria√ß√£o do Database no Atlas\n",
    "\n",
    "Esta c√©lula cria ou localiza o database no Apache Atlas que representar√° nosso PostgreSQL.\n",
    "\n",
    "**O que faz:**\n",
    "- Tenta criar um novo database no Atlas usando a API REST\n",
    "- Se j√° existir, busca o GUID do database existente\n",
    "- Retorna o identificador √∫nico (GUID) do database para usar nas pr√≥ximas etapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database_in_atlas():\n",
    "    \"\"\"Cria ou localiza database no Atlas\"\"\"\n",
    "    # Payload JSON para criar entidade do tipo 'hive_db' no Atlas\n",
    "    db_payload = {\n",
    "        \"entities\": [{\n",
    "            \"typeName\": \"hive_db\",                    # Tipo de entidade (database)\n",
    "            \"attributes\": {\n",
    "                \"name\": \"northwind_postgres\",          # Nome do database\n",
    "                \"qualifiedName\": \"northwind_postgres@cluster1\",  # Nome √∫nico global\n",
    "                \"clusterName\": \"cluster1\"              # Nome do cluster\n",
    "            },\n",
    "            \"guid\": -1                                 # GUID tempor√°rio (ser√° gerado pelo Atlas)\n",
    "        }]\n",
    "    }\n",
    "    \n",
    "    # Tenta criar o database via API REST do Atlas\n",
    "    response = requests.post(f\"{ATLAS_URL}/api/atlas/v2/entity/bulk\", \n",
    "                            json=db_payload, auth=auth)\n",
    "    \n",
    "    # Se cria√ß√£o foi bem-sucedida, retorna o GUID gerado\n",
    "    if response.status_code in [200, 201]:\n",
    "        result = response.json()\n",
    "        if 'mutatedEntities' in result and 'CREATE' in result['mutatedEntities']:\n",
    "            return result['mutatedEntities']['CREATE'][0]['guid']\n",
    "    \n",
    "    # Se n√£o conseguiu criar, busca database existente\n",
    "    search_response = requests.get(f\"{ATLAS_URL}/api/atlas/v2/search/basic\", \n",
    "                                 params={\"query\": \"northwind_postgres\"}, auth=auth)\n",
    "    \n",
    "    # Processa resultado da busca\n",
    "    if search_response.status_code == 200:\n",
    "        entities = search_response.json().get('entities', [])\n",
    "        # Filtra apenas entidades do tipo 'hive_db'\n",
    "        db_entities = [e for e in entities if e.get('typeName') == 'hive_db']\n",
    "        if db_entities:\n",
    "            return db_entities[0]['guid']  # Retorna GUID do primeiro database encontrado\n",
    "    \n",
    "    return None  # Retorna None se n√£o conseguiu criar nem encontrar\n",
    "\n",
    "# Executa cria√ß√£o/busca do database\n",
    "db_guid = create_database_in_atlas()\n",
    "print(f\"‚úÖ Database GUID: {db_guid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 4: Cataloga√ß√£o Completa de Tabelas e Colunas\n",
    "\n",
    "Esta c√©lula implementa a cataloga√ß√£o integrada de tabelas com suas colunas no Atlas.\n",
    "\n",
    "**O que faz:**\n",
    "- Remove tabelas existentes para evitar duplicatas\n",
    "- Cria tabelas e colunas em uma √∫nica opera√ß√£o\n",
    "- Usa GUIDs negativos para referenciar tabelas nas colunas\n",
    "- Garante que as colunas apare√ßam no schema das tabelas no Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catalog_data(table_name, columns, db_guid):\n",
    "    \"\"\"Recria tabela com colunas integradas no Atlas\"\"\"\n",
    "    \n",
    "    # Primeiro, remove tabela existente se houver\n",
    "    search_response = requests.get(f\"{ATLAS_URL}/api/atlas/v2/search/basic\", \n",
    "                                  params={\"query\": table_name}, auth=auth)\n",
    "    \n",
    "    # Se encontrou entidades, deleta as tabelas existentes\n",
    "    if search_response.status_code == 200:\n",
    "        entities = search_response.json().get('entities', [])\n",
    "        for entity in entities:\n",
    "            # Verifica se √© uma tabela com o nome exato\n",
    "            if entity.get('typeName') == 'hive_table' and entity.get('displayText') == table_name:\n",
    "                # Deleta a entidade usando seu GUID\n",
    "                requests.delete(f\"{ATLAS_URL}/api/atlas/v2/entity/guid/{entity['guid']}\", auth=auth)\n",
    "                print(f\"  üóëÔ∏è Deletada tabela existente: {table_name}\")\n",
    "    \n",
    "    # Lista para armazenar todas as entidades (tabela + colunas)\n",
    "    entities = []\n",
    "    \n",
    "    # Cria entidade da tabela\n",
    "    table_entity = {\n",
    "        \"typeName\": \"hive_table\",                    # Tipo de entidade (tabela)\n",
    "        \"attributes\": {\n",
    "            \"name\": table_name,                       # Nome da tabela\n",
    "            \"qualifiedName\": f\"northwind_postgres.{table_name}@cluster1\",  # Nome √∫nico\n",
    "            \"db\": {\"guid\": db_guid},                  # Refer√™ncia ao database pai\n",
    "            \"owner\": \"postgres\"                       # Propriet√°rio da tabela\n",
    "        },\n",
    "        \"guid\": -1                                    # GUID tempor√°rio negativo\n",
    "    }\n",
    "    entities.append(table_entity)\n",
    "    \n",
    "    # Cria entidades das colunas\n",
    "    for i, col in enumerate(columns, 1):              # Enumera come√ßando do 1\n",
    "        column_entity = {\n",
    "            \"typeName\": \"hive_column\",                # Tipo de entidade (coluna)\n",
    "            \"attributes\": {\n",
    "                \"name\": col['column_name'],            # Nome da coluna\n",
    "                \"qualifiedName\": f\"northwind_postgres.{table_name}.{col['column_name']}@cluster1\",\n",
    "                \"table\": {\"guid\": -1},                 # Refer√™ncia √† tabela (GUID -1)\n",
    "                \"type\": col['data_type'],              # Tipo de dados da coluna\n",
    "                \"position\": i                          # Posi√ß√£o da coluna na tabela\n",
    "            },\n",
    "            \"guid\": -(i+1)                             # GUID tempor√°rio negativo √∫nico\n",
    "        }\n",
    "        entities.append(column_entity)\n",
    "    \n",
    "    # Envia todas as entidades (tabela + colunas) em uma √∫nica requisi√ß√£o\n",
    "    payload = {\"entities\": entities}\n",
    "    response = requests.post(f\"{ATLAS_URL}/api/atlas/v2/entity/bulk\", \n",
    "                           json=payload, auth=auth)\n",
    "    \n",
    "    # Verifica se a cria√ß√£o foi bem-sucedida\n",
    "    if response.status_code in [200, 201]:\n",
    "        result = response.json()\n",
    "        created = result.get('mutatedEntities', {}).get('CREATE', [])\n",
    "        print(f\"  ‚úÖ {table_name}: {len(created)} entidades criadas\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"  ‚ùå Erro {table_name}: {response.status_code}\")\n",
    "        return False\n",
    "\n",
    "# Executa cataloga√ß√£o de todas as tabelas\n",
    "if db_guid:\n",
    "    print(f\"üîÑ Recriando {len(postgres_metadata)} tabelas com colunas integradas...\")\n",
    "    success_count = 0\n",
    "    \n",
    "    # Processa cada tabela individualmente\n",
    "    for table_name, columns in postgres_metadata.items():\n",
    "        print(f\"\\nüìã Processando: {table_name}\")\n",
    "        success = catalog_data(table_name, columns, db_guid)\n",
    "        if success:\n",
    "            success_count += 1\n",
    "    \n",
    "    print(f\"\\n‚úÖ {success_count}/{len(postgres_metadata)} tabelas recriadas com sucesso!\")\n",
    "    print(\"   Verifique no Atlas: todas as colunas devem aparecer no schema das tabelas\")\n",
    "else:\n",
    "    print(\"‚ùå Database n√£o dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 5: Verifica√ß√£o Final do Cat√°logo\n",
    "\n",
    "Esta c√©lula verifica o resultado final da cataloga√ß√£o no Apache Atlas.\n",
    "\n",
    "**O que faz:**\n",
    "- Busca todas as entidades relacionadas ao nosso projeto\n",
    "- Conta databases, tabelas e colunas catalogadas\n",
    "- Exibe estat√≠sticas finais e link para acesso ao Atlas\n",
    "- Confirma que a cataloga√ß√£o foi bem-sucedida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca todas as entidades relacionadas ao projeto northwind_postgres\n",
    "search_response = requests.get(f\"{ATLAS_URL}/api/atlas/v2/search/basic\", \n",
    "                              params={\"query\": \"*\", \"limit\": 200}, auth=auth)\n",
    "\n",
    "# Processa e exibe resultados da cataloga√ß√£o\n",
    "if search_response.status_code == 200:\n",
    "    entities = search_response.json().get('entities', [])\n",
    "    \n",
    "    # Filtra entidades por tipo e status ativo\n",
    "    databases = [e for e in entities if e.get('typeName') == 'hive_db' and e.get('status') == 'ACTIVE']\n",
    "    tables = [e for e in entities if e.get('typeName') == 'hive_table' and e.get('status') == 'ACTIVE']\n",
    "    columns = [e for e in entities if e.get('typeName') == 'hive_column' and e.get('status') == 'ACTIVE']\n",
    "    \n",
    "    # Exibe estat√≠sticas finais\n",
    "    print(\"üìä Resultado Final do Cat√°logo:\")\n",
    "    print(f\"  üóÑÔ∏è Databases: {len(databases)}\")\n",
    "    print(f\"  üìã Tabelas: {len(tables)}\")\n",
    "    print(f\"  üìù Colunas: {len(columns)}\")\n",
    "    \n",
    "    # Mostra algumas tabelas como exemplo\n",
    "    if tables:\n",
    "        print(\"\\nüìã Tabelas catalogadas (primeiras 5):\")\n",
    "        for i, table in enumerate(tables[:5], 1):\n",
    "            print(f\"  {i}. {table.get('displayText')}\")\n",
    "    \n",
    "    # Informa√ß√µes de acesso ao Atlas\n",
    "    print(f\"\\nüéâ Acesse o Atlas: http://localhost:21000\")\n",
    "    print(f\"   Usu√°rio: admin | Senha: admin\")\n",
    "    print(f\"\\nüí° Dica: Navegue at√© 'Search' e busque por 'northwind_postgres' para ver o cat√°logo completo\")\n",
    "else:\n",
    "    print(f\"‚ùå Erro na verifica√ß√£o: {search_response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√£o\n",
    "\n",
    "### O que Conseguimos\n",
    "\n",
    "- **Extra√ß√£o Autom√°tica**: Metadados do PostgreSQL via `information_schema`  \n",
    "- **Cataloga√ß√£o Completa**: 14 tabelas + colunas no Apache Atlas  \n",
    "- **Integra√ß√£o Perfeita**: Colunas vis√≠veis no schema das tabelas  \n",
    "- **API REST**: Automa√ß√£o via APIs do Atlas  \n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "\n",
    "- **Classifica√ß√µes**: Adicionar tags e classifica√ß√µes aos dados\n",
    "- **Linhagem**: Mapear transforma√ß√µes e fluxos de dados\n",
    "- **Gloss√°rio**: Criar defini√ß√µes de neg√≥cio para termos\n",
    "- **Automa√ß√£o**: Integrar com pipelines de CI/CD\n",
    "\n",
    "### Benef√≠cios Alcan√ßados\n",
    "\n",
    "- **Descoberta**: Dados facilmente encontr√°veis  \n",
    "- **Documenta√ß√£o**: Metadados estruturados e acess√≠veis  \n",
    "- **Governan√ßa**: Base para pol√≠ticas de dados  \n",
    "- **Produtividade**: Redu√ß√£o do tempo de an√°lise  \n",
    "\n",
    "**Parab√©ns! Voc√™ criou seu primeiro cat√°logo de dados com Apache Atlas!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
